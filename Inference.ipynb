{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brave-payment",
   "metadata": {},
   "source": [
    "# 1. PyTorch Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-banner",
   "metadata": {},
   "source": [
    "_NOTE_: If you run this notebook on Google Colab or any similar services, there's a possibility that they might have `pytorch` package installed. But if it's on a local machine, run the following cells (depends on what type of machine you have)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-executive",
   "metadata": {},
   "source": [
    "## 1.1. CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-guess",
   "metadata": {},
   "source": [
    "## 1.2. GPU (an alternative to 1.1, if you have a high-end NVIDIA GPU with support of CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-vehicle",
   "metadata": {},
   "source": [
    "# 2. Checking for models and downloading them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-collins",
   "metadata": {},
   "source": [
    "_NOTE_: If you have downloaded the models from our [repository], then just create a folder called `models` and put your model files inside it. Otherwise, run the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-companion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models are there, where are you?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if 'models' in os.listdir():\n",
    "    if os.listdir('models'):\n",
    "        print('Models are there, where are you?')\n",
    "    else:\n",
    "        !cd models && wget https://persianocr.cam/models/letters.pt\n",
    "        !cd models && wget https://persianocr.cam/models/numbers.pt\n",
    "else:\n",
    "    os.mkdir('models')\n",
    "    !cd models && wget https://persianocr.cam/models/letters.pt\n",
    "    !cd models && wget https://persianocr.cam/models/numbers.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-national",
   "metadata": {},
   "source": [
    "# 3. Loading the models for inference and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-level",
   "metadata": {},
   "source": [
    "## 3.1. Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attached-private",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-broadway",
   "metadata": {},
   "source": [
    "## 3.2. Resolving SSL problem (Optional and Occasional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-rider",
   "metadata": {},
   "source": [
    "Only run this cell if:\n",
    "\n",
    "1. You're on a Mac. Most of macOS users got errors regarding SSL problems (so did I)\n",
    "2. You get SSL related errors in other OSs. \n",
    "\n",
    "If you're on Colab or similar services, you obviously don't need this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "through-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-talent",
   "metadata": {},
   "source": [
    "## 3.3. Functions for text extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-white",
   "metadata": {},
   "source": [
    "### 3.3.1. Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compound-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "_translator = str.maketrans(\"1234567890\", \"۱۲۳۴۵۶۷۸۹۰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painful-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def latin_to_persian(number):\n",
    "    return number.translate(_translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "invisible-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chars(result):\n",
    "    df = result.pandas().xyxy[0] # because we only need the first one\n",
    "    df = df.sort_values('xmin') # sorts them write to left'\n",
    "    \n",
    "    output_string = []\n",
    "    for name, confidence in zip(df['name'], df['confidence']):\n",
    "        if confidence > 0.8:\n",
    "            output_string.append(name)\n",
    "            \n",
    "    output_string = ''.join(output_string)\n",
    "    output_string = latin_to_persian(output_string)\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-directive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
